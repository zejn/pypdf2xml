#!/usr/bin/python
# *-* coding: utf-8 *-*
import csv
import re
import sys
import urllib
import HTMLParser

from StringIO import StringIO
import lxml.etree, lxml.html
#from postavke import load_postavke

h = HTMLParser.HTMLParser()

pdfxml = open(sys.argv[1],'r').read()
root = lxml.etree.fromstring(pdfxml)

fontspecs = { }
rows = [ ]

for pagenum, page in enumerate(root):
    #if pagenum == 0:
    #    continue
    assert page.tag == 'page'
    pagelines = {}
    for v in page:
        if v.tag == 'text':
            text = re.match('(?s)<text.*?>(.*?)</text>', lxml.etree.tostring(v)).group(1)   # there has to be a better way here to get the contents
            #print >> sys.stderr, text
            left = int(v.attrib.get('left'))
            top  = int(v.attrib.get('top'))
            if pagelines.has_key(top-1): # fix some off-by-one placement issues, which make some text span over two lines where it should be in one
                top = top - 1
            elif pagelines.has_key(top+1):
                top = top + 1
            line = pagelines.setdefault(top, [])
            line.append((left, text))
    ordered = list(sorted([(k, sorted(v)) for k,v in pagelines.iteritems()], reverse=True))
    #rows.extend([i[1] for i in ordered])
    rows.extend(ordered)

#print >> sys.stderr, rows[:20]

#pdata = load_postavke()
records = []
splitline = 300
# split into cols
pause_output = False # for footer and header
for topoffset, line in rows:
    firstoffset = line[0][0]
    firstcol = []
    secondcol = []
    for item in line:
        if item[0] < splitline:
            firstcol.append(item[1])
        else:
            secondcol.append(item[1])

    rec = [h.unescape(' '.join(firstcol))]
    rec = [i.replace('<b>', '').replace('</b>', '').replace('<i>', '').replace('</i>', '') for i in rec]
    first = ''.join(rec)
    records.append([topoffset, firstoffset, first])
    #print records[-1]




# write CSV
csvdata = StringIO()
w = csv.writer(csvdata, quotechar='"', quoting=csv.QUOTE_ALL)
for r in records:
    w.writerow([unicode(i).encode('utf-8') for i in r])

print csvdata.getvalue()
